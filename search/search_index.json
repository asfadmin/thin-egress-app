{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Thin Egress App Purpose of TEA TEA is a fully Earthdata Cloud (EDC) compliant application to enable distribution of EOSDIS data from Amazon S3 while ensuring data providers have all the tools, controls and metrics required for data distribution restriction and reporting compliance. TEA Distribution supports only static S3 data, and is not intended for service-style or dynamic data distribution. This documentation is intended to support stand-alone TEA deployments, and while it may be a valuable tool for TEA deployments provisioned through Cumulus, we suggest you visit the Cumulus documentation for guidance on using and customizing TEA from within Cumulus. Make it better Join us on this journey! Together we can make TEA better! Contribute We love contributions from outside the team! We have 2 requirements for accepting contributions: All contributions should conform to our TEA Vision Contributions should come with unit tests to validate the feature Requesting features If you have a feature you'd like to request, first confirm the feature aligns with our TEA Vision . If you think the feature belongs in TEA, you have TWO options: Request the feature using Github Issue Request the feature in the #tea-pot Slack Channel History of TEA TEA was originally designed as a lightweight S3 distribution application with Earthdata Login (EDL) support meant to help test and evaluate the (then) forethcoming NGAP Enterprise Egress platform. TEA leveraged much of the design and features of ASF's original full-featured s3 distribution app, without any of the throttling or egress tracking capabilities. Without the need to do throttling, TEA ditched docker/nginx/ECS in favor of the lighter, more nimble Lambda + API Gateway architecture.","title":"Home"},{"location":"#thin-egress-app","text":"","title":"Thin Egress App"},{"location":"#purpose-of-tea","text":"TEA is a fully Earthdata Cloud (EDC) compliant application to enable distribution of EOSDIS data from Amazon S3 while ensuring data providers have all the tools, controls and metrics required for data distribution restriction and reporting compliance. TEA Distribution supports only static S3 data, and is not intended for service-style or dynamic data distribution. This documentation is intended to support stand-alone TEA deployments, and while it may be a valuable tool for TEA deployments provisioned through Cumulus, we suggest you visit the Cumulus documentation for guidance on using and customizing TEA from within Cumulus.","title":"Purpose of TEA"},{"location":"#make-it-better","text":"Join us on this journey! Together we can make TEA better!","title":"Make it better"},{"location":"#contribute","text":"We love contributions from outside the team! We have 2 requirements for accepting contributions: All contributions should conform to our TEA Vision Contributions should come with unit tests to validate the feature","title":"Contribute"},{"location":"#requesting-features","text":"If you have a feature you'd like to request, first confirm the feature aligns with our TEA Vision . If you think the feature belongs in TEA, you have TWO options: Request the feature using Github Issue Request the feature in the #tea-pot Slack Channel","title":"Requesting features"},{"location":"#history-of-tea","text":"TEA was originally designed as a lightweight S3 distribution application with Earthdata Login (EDL) support meant to help test and evaluate the (then) forethcoming NGAP Enterprise Egress platform. TEA leveraged much of the design and features of ASF's original full-featured s3 distribution app, without any of the throttling or egress tracking capabilities. Without the need to do throttling, TEA ditched docker/nginx/ECS in favor of the lighter, more nimble Lambda + API Gateway architecture.","title":"History of TEA"},{"location":"configuration/","text":"Configuration Bucket Mapping At the heart of TEA is the concept of the Bucket Map. This YAML file tells TEA how to map URLs to buckets and how to control access to data in buckets. Mapping depths are arbitrary and dynamically account for object path prefixes. Bucket maps are case sensitive! When working with a bucket map, it is important to remember that bucket names are relative to the optional bucket prefix TEA parameter. If a bucket prefix is supplied, that value is prepended to any bucket name. This optional feature is intended to allow bucket maps to be used in multiple maturities (e.g. Sandbox, SIT, UAT, Prod) where bucket names are consistent across maturities given a specific bucket prefix. Assume the following bucket map: MAP: path1: bucket-path-1 path2: path2a: bucket-path-2a path2b: bucket-path-2b path3: path3a: path3ai: bucket-path-3ai You can derive the following object -> URL mappings: s3://bucket-path-1/object.txt => https://[APP-BASE-URL]/path1/object.txt s3://bucket-path-2a/file.ext => https://[APP-BASE-URL]/path2/path2a/file.ext s3://bucket-path-2b/low-res/browse.jpg => https://[APP-BASE-URL]/path2/path2b/low-res/browse.jpg s3://bucket-path-3ai/some-product.h5 => https://[APP-BASE-URL]/path3/path3a/path3ai/some-product.h5 It is NOT possible to have distribution at the app root. That is, s3://bucket-path-1/object.txt cannot be configured to be distributed at https://[APP-BASE-URL]/object.txt . Custom Headers Custom HTTP response headers can be added to bucket mappings: MAP: path1: bucket: bucket-path-1 headers: Content-Type: \"text/plain\" EDL Access Control By default, all buckets are assumed to require a user to log into Earthdata Login to download data. However, there are two options to change that behavior Public Buckets Buckets can be made public by adding a PUBLIC_BUCKETS block: MAP: browse: browse-bucket PUBLIC_BUCKETS: browse-bucket: \"Internal only Comment about browse being public\" In the above example, accessing https://[APP-BASE-URL]/browse/some-browse-image.jpg would not require EDL authentication, however, if a user was already logged in, the downloads would be tagged with that users EDL User ID. Private Buckets TEA download can also be restricted to users who belonging to an EDL Application User Group. This allows App and Data owners to specify a discrete list of specially approved users who can download data. MAP: pre-commission: pre-comission-data-bucket PRIVATE_BUCKETS: pre-commission-data-bucket: - internal_users - external_team In the example above, TEA will ensure that a user attempt to download https://[APP-BASE-URL]/pre-commission/not-yet-public.zip belongs to either the App User Group internal_users or external_team . Users who are not in one or both of those groups will not be granted a download. Public and Private Prefixes In addition you specifying whole buckets as Public or Private, you can also use object prefixing to control access: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users - external_team In the above example, while access to data in data-bucket requires EDL App group access to one of the specified groups, accessing an object with the prefix browse/ will not require any auth. TEA will always check the rules from most deeply nested to most shallow. So for example, in this bucket map: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/external/public/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users data-bucket/external/: - internal_users - external_team Any data in the prefix external/public/ will be public, data in the prefix external/ but not in the prefix external/public/ will be available to users in either of the defined EDL App groups, and everything else in the bucket will be available to users in the internal_users group only. S3 Direct Access Compatibility Some access configurations supported by the standard HTTP methods are not allowed when S3 direct access is enabled. Of note: The first prefix in the bucket map will need to be set to the most restrictive access level and subsequent prefixes must have access levels that become successively more open. This is due to a limitation with how IAM policies work (For more information, see S3 direct access ). Public buckets will require EDL authentication for S3 direct access. e.g. \"Browse image\" All of the bucket maps shown above are compatible with S3 direct access; however, long time users of TEA might recognize the following configuration example from previous versions which will be rejected when S3 direct access is enabled. Bad Example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: # Since no permission is specified for `data-bucket/`, the default is used # which allows access to any authenticated user. Therefore, adding a # prefix `pre-commission-data/` that is more restrictive will break IAM # compatibility. data-bucket/pre-commission-data/: - internal_users - external_team To fix this, the bucket map could be modified as follows: Good Example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users - external_team # The following rule is redundant, but might not be in the presence of # other rules. data-bucket/pre-commission-data/: - internal_users - external_team S3 Direct Access TEA can be deployed with an /s3credentials endpoint (See Enabling S3 direct access ) for facilitating S3 direct access. Credentials handed out over this endpoint will have both s3:ListBucket and s3:GetObject permissions for in-region requests to prefixes configured in the bucket map. For example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/pre-commission-data/: - internal_users - external_team Using this bucket map, the /s3credentials endpoint would return credentials allowing in-region access to any objects in data-bucket EXCEPT objects that have the pre-commission-data/ prefix to any logged in user. Any user in the internal_users or external_team groups would be able to use their credentials to access all data in the bucket. Custom Templating You may optionally create your own jinja2 html templates. If no custom templates are supplied in the HtmlTemplateDir subdirectory of the ConfigBucket bucket, ultra-generic (and a little annoying!) default templates are used. base.html This is the base template. Blocks: pagetitle : Gets inserted inside the <title></title> element content : Content payload fed into the template. root.html Child template. Gets called by / and /logout for 200 responses. Variables: title : page title URS_URL : used to make the login link STAGE : used to make a URL back to the egress app profile : in the default template, profile.first_name and profile.last_name are used to greet a logged-in user. The entire profile dict is available to the template. contentstring : any text can go here error.html Child template that gets called when various 400 type errors happen. Variables: title : page title status_code : http status code goes here contentstring : any text can go here profile.html Child template that displays profile info. Only used for debugging in dev. Shared Token Support TEA can accept a shared EDL Token as an Authorization (Bearer Token) method. To enable this behavior, EDL Apps (Service + TEA) must belong to a shared EDL App Group. Processing a shared token is temporally expensive. After the initial request, subsequent Service->TEA data requests should reuse cookies. EULA enforcement is preserved with shared tokens. Using custom domain names There is a process by which you can request an Alternate Domain name to your CloudFront endpoint. If you do this, you'll need to update the DomainName , CookieName , and DomainCertArn parameters of your TEA Deploment . Updating configuration of a live TEA If the bucket map is updated, because of caching it can take quite some time before TEA loads it. If you would like to force TEA to load the new configs immediately, invoke the bumper lambda: aws lambda invoke --function-name=\"${STACK_NAME}-BumperLambda\" output.txt","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"configuration/#bucket-mapping","text":"At the heart of TEA is the concept of the Bucket Map. This YAML file tells TEA how to map URLs to buckets and how to control access to data in buckets. Mapping depths are arbitrary and dynamically account for object path prefixes. Bucket maps are case sensitive! When working with a bucket map, it is important to remember that bucket names are relative to the optional bucket prefix TEA parameter. If a bucket prefix is supplied, that value is prepended to any bucket name. This optional feature is intended to allow bucket maps to be used in multiple maturities (e.g. Sandbox, SIT, UAT, Prod) where bucket names are consistent across maturities given a specific bucket prefix. Assume the following bucket map: MAP: path1: bucket-path-1 path2: path2a: bucket-path-2a path2b: bucket-path-2b path3: path3a: path3ai: bucket-path-3ai You can derive the following object -> URL mappings: s3://bucket-path-1/object.txt => https://[APP-BASE-URL]/path1/object.txt s3://bucket-path-2a/file.ext => https://[APP-BASE-URL]/path2/path2a/file.ext s3://bucket-path-2b/low-res/browse.jpg => https://[APP-BASE-URL]/path2/path2b/low-res/browse.jpg s3://bucket-path-3ai/some-product.h5 => https://[APP-BASE-URL]/path3/path3a/path3ai/some-product.h5 It is NOT possible to have distribution at the app root. That is, s3://bucket-path-1/object.txt cannot be configured to be distributed at https://[APP-BASE-URL]/object.txt .","title":"Bucket Mapping"},{"location":"configuration/#custom-headers","text":"Custom HTTP response headers can be added to bucket mappings: MAP: path1: bucket: bucket-path-1 headers: Content-Type: \"text/plain\"","title":"Custom Headers"},{"location":"configuration/#edl-access-control","text":"By default, all buckets are assumed to require a user to log into Earthdata Login to download data. However, there are two options to change that behavior","title":"EDL Access Control"},{"location":"configuration/#public-buckets","text":"Buckets can be made public by adding a PUBLIC_BUCKETS block: MAP: browse: browse-bucket PUBLIC_BUCKETS: browse-bucket: \"Internal only Comment about browse being public\" In the above example, accessing https://[APP-BASE-URL]/browse/some-browse-image.jpg would not require EDL authentication, however, if a user was already logged in, the downloads would be tagged with that users EDL User ID.","title":"Public Buckets"},{"location":"configuration/#private-buckets","text":"TEA download can also be restricted to users who belonging to an EDL Application User Group. This allows App and Data owners to specify a discrete list of specially approved users who can download data. MAP: pre-commission: pre-comission-data-bucket PRIVATE_BUCKETS: pre-commission-data-bucket: - internal_users - external_team In the example above, TEA will ensure that a user attempt to download https://[APP-BASE-URL]/pre-commission/not-yet-public.zip belongs to either the App User Group internal_users or external_team . Users who are not in one or both of those groups will not be granted a download.","title":"Private Buckets"},{"location":"configuration/#public-and-private-prefixes","text":"In addition you specifying whole buckets as Public or Private, you can also use object prefixing to control access: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users - external_team In the above example, while access to data in data-bucket requires EDL App group access to one of the specified groups, accessing an object with the prefix browse/ will not require any auth. TEA will always check the rules from most deeply nested to most shallow. So for example, in this bucket map: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/external/public/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users data-bucket/external/: - internal_users - external_team Any data in the prefix external/public/ will be public, data in the prefix external/ but not in the prefix external/public/ will be available to users in either of the defined EDL App groups, and everything else in the bucket will be available to users in the internal_users group only.","title":"Public and Private Prefixes"},{"location":"configuration/#s3-direct-access-compatibility","text":"Some access configurations supported by the standard HTTP methods are not allowed when S3 direct access is enabled. Of note: The first prefix in the bucket map will need to be set to the most restrictive access level and subsequent prefixes must have access levels that become successively more open. This is due to a limitation with how IAM policies work (For more information, see S3 direct access ). Public buckets will require EDL authentication for S3 direct access. e.g. \"Browse image\" All of the bucket maps shown above are compatible with S3 direct access; however, long time users of TEA might recognize the following configuration example from previous versions which will be rejected when S3 direct access is enabled. Bad Example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: # Since no permission is specified for `data-bucket/`, the default is used # which allows access to any authenticated user. Therefore, adding a # prefix `pre-commission-data/` that is more restrictive will break IAM # compatibility. data-bucket/pre-commission-data/: - internal_users - external_team To fix this, the bucket map could be modified as follows: Good Example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/: - internal_users - external_team # The following rule is redundant, but might not be in the presence of # other rules. data-bucket/pre-commission-data/: - internal_users - external_team","title":"S3 Direct Access Compatibility"},{"location":"configuration/#s3-direct-access","text":"TEA can be deployed with an /s3credentials endpoint (See Enabling S3 direct access ) for facilitating S3 direct access. Credentials handed out over this endpoint will have both s3:ListBucket and s3:GetObject permissions for in-region requests to prefixes configured in the bucket map. For example: MAP: data-path: data-bucket PUBLIC_BUCKETS: data-bucket/browse/: \"Browse image\" PRIVATE_BUCKETS: data-bucket/pre-commission-data/: - internal_users - external_team Using this bucket map, the /s3credentials endpoint would return credentials allowing in-region access to any objects in data-bucket EXCEPT objects that have the pre-commission-data/ prefix to any logged in user. Any user in the internal_users or external_team groups would be able to use their credentials to access all data in the bucket.","title":"S3 Direct Access"},{"location":"configuration/#custom-templating","text":"You may optionally create your own jinja2 html templates. If no custom templates are supplied in the HtmlTemplateDir subdirectory of the ConfigBucket bucket, ultra-generic (and a little annoying!) default templates are used. base.html This is the base template. Blocks: pagetitle : Gets inserted inside the <title></title> element content : Content payload fed into the template. root.html Child template. Gets called by / and /logout for 200 responses. Variables: title : page title URS_URL : used to make the login link STAGE : used to make a URL back to the egress app profile : in the default template, profile.first_name and profile.last_name are used to greet a logged-in user. The entire profile dict is available to the template. contentstring : any text can go here error.html Child template that gets called when various 400 type errors happen. Variables: title : page title status_code : http status code goes here contentstring : any text can go here profile.html Child template that displays profile info. Only used for debugging in dev.","title":"Custom Templating"},{"location":"configuration/#shared-token-support","text":"TEA can accept a shared EDL Token as an Authorization (Bearer Token) method. To enable this behavior, EDL Apps (Service + TEA) must belong to a shared EDL App Group. Processing a shared token is temporally expensive. After the initial request, subsequent Service->TEA data requests should reuse cookies. EULA enforcement is preserved with shared tokens.","title":"Shared Token Support"},{"location":"configuration/#using-custom-domain-names","text":"There is a process by which you can request an Alternate Domain name to your CloudFront endpoint. If you do this, you'll need to update the DomainName , CookieName , and DomainCertArn parameters of your TEA Deploment .","title":"Using custom domain names"},{"location":"configuration/#updating-configuration-of-a-live-tea","text":"If the bucket map is updated, because of caching it can take quite some time before TEA loads it. If you would like to force TEA to load the new configs immediately, invoke the bumper lambda: aws lambda invoke --function-name=\"${STACK_NAME}-BumperLambda\" output.txt","title":"Updating configuration of a live TEA"},{"location":"deploying/","text":"Deploying It is recommended to deploy any production system using an Infrastructure As Code (IAC) solution such as terraform or AWS CloudFormation. The commands in this section exist to help you get started and understand how the TEA infrastructure works, but do not necessarily represent the best way to deploy TEA in production. Quickstart You can install the TEA command line tool to get a TEA stack up and running as fast as possible. It is not recommended to use this method for production deployments. Installation We recommend using pipx to simplify virtual environment management for command line tools. pipx install provides an interface similar to pip install which means the following commands can be run using either pipx or pip if you prefer to do your own virtual environment management. To install the TEA CLI using git over SSH: pipx install git+ssh://git@github.com/asfadmin/thin-egress-app.git#subdirectory=src/tea-cli Or, to install the TEA CLI using git over HTTPS: pipx install git+https://github.com/asfadmin/thin-egress-app.git#subdirectory=src/tea-cli Using the TEA CLI NOTE: For a detailed, up to date list of available functionality run: tea --help To quickly get a TEA stack up and running use the quickdeploy subcommand: tea quickdeploy This will guide you through an interactive prompt where you can choose to deploy various resources needed to set up a basic functioning TEA stack. Each step might prompt you for certain input configuration which can also be passed on the command line. See tea quickdeploy --help for a list of argument names. Getting TEA Code Major release documentation can be found on github . s3://asf.public.code All public releases of ASF code are made available via the public bucket asf.public.code . Each build has 4 files: tea-cloudformation-build.#.yaml - CloudFormation template tea-code-build.#.zip - Lambda App Python Code tea-dependencylayer-build.#.zip - Lambda layer Python Dependency Code tea-terraform-build.#.zip - TEA as a Terraform module (For cumulus!) Deployment Steps At its core, TEA uses a CloudFormation template to deploy all of its resources to AWS. Additionally, there is an available Terraform module that can be used on its own, or as an add-on to Cumulus. Secrets Setup Two secrets manager objects are required for TEA to function properly: URS Auth Creds Secret To set up the URS Auth secret object, You'll need these parameters: UrsId can be found on your SSO application's URS home page as Client ID . UrsAuth is the UID for your URS SSO app and password separated by a colon. You can create the value with the command below. See EDL's Doumentation for more details. Encode the Creds UrsAuth=$(echo -n \"<App UID>:<App Password>\" | base64) UrsId=\"<Client ID>\" Write the base64 encoded keys into a json file: cat << EOL > urscreds.json { \"UrsId\": \"$UrsAuth\", \"UrsAuth\": \"$UrsId\" } EOL Create the secret in AWS, referencing the json file created above aws $AWSENV secretsmanager create-secret --name urs_creds_for_tea \\ --description \"URS creds for TEA app\" \\ --secret-string file://urscreds.json JWT Cookie Secret JWT secrets allow multiple TEA instances to encode and decode each others JWT cookies. This helps reduce the number of times EDL Authentication needs to happen. There are many ways to create JWS Secrets, here is one example: First, Create a key pair and b64 encode them: ssh-keygen -t rsa -b 4096 -m PEM -f ./jwtcookie.key rsa_priv_key=$(openssl base64 -in jwtcookie.key -A) rsa_pub_key=$(openssl base64 -in jwtcookie.key.pub -A) Put the base-64 encoded keys into a json file like so: cat << EOL > jwtkeys.json { \"rsa_priv_key\": \"$rsa_priv_key\", \"rsa_pub_key\": \"$rsa_pub_key\" } EOL Create the secret in AWS, referencing the json file created above aws $AWSENV secretsmanager create-secret --name jwt_secret_for_tea \\ --description \"RS256 keys for TEA app JWT cookies\" \\ --secret-string file://jwtkeys.json From CloudFormation All Parameters App Settings : Loglevel - How verbose the logging should be Logtype - How log entries are formed. Use json in conjunction with log analysis tools. Use flat for human debugging. Maturity - Maturity, mostly for logs ConfigBucket - S3 bucket where configuration files (bucket map, templates) are kept HtmlTemplateDir - (OPTIONAL) Subdirectory of ConfigBucket where templates can be found StageName - API Gateway Stage value EnableApiGatewayLogToCloudWatch - Whether or not API Gateway logs should be dumped EnableS3CredentialsEndpoint - Whether or not to deploy the /s3credentials endpoint for s3 direct access. Domain Settings : DomainName - (OPTIONAL) domain name as a user will access it (ie CloudFront, CNAME, etc) CookieDomain - (OPTIONAL) domain name value for minting cookies DomainCertArn - (OPTIONAL) Arn to a AWS ACM SSL Cert for HTTPS access UseCorsCookieDomain - If True , and CookieDomain is set, this enables CORS Response Headers Lambda Code : LambdaCodeS3Bucket - S3 bucket where Lambda code zip files are kept LambdaCodeS3Key - Object name of Lambda code zip LambdaCodeDependencyArchive - Object name of Lambda Dependency Layer zip LambdaTimeout - Lambda timeout in seconds LambdaMemory - The amount of memory available to the function during execution. Must be multiple of 64. Minimum: 128. Max: 3008. Default 1792. URS Settings : URSAuthCredsSecretName - URS Auth Creds Secret AuthBaseUrl - Which maturity of URS to hit Data Bucket Setup : BucketnamePrefix - (OPTIONAL) Bucket prefix value (see Bucket Mapping ) BucketMapFile - bucket map YAML file (see Bucket Mapping ) UseReverseBucketMap - Ignore this value! DownloadRoleArn - (OPTIONAL) Pre-created IAM Role for minting presigned urls Leave blank to create a new role for deployment DownloadRoleInRegionArn - (OPTIONAL) Pre-created IAM Role for minting IN-REGION presigned urls Leave blank to create a new role for deployment SuppressHeadCheck - Disable the pre-sign object validation. Enable for speedier access. Session Settings : SessionTTL - How long, in seconds, JWT Cookies are valid for JwtAlgo - JWT Signing algorithm JwtKeySecretName - JWT Cookie Secret NGAP Integration : \u26a0\ufe0f These are REQUIRED for EDC Deployments. See VPC and Networking PrivateVPC - Private VPC ID in which we create resources ( $VPCID ) VPCSecurityGroupIDs - Security group ( $SUBNETID ) VPCSubnetIDs - VPC Subnets to deploy into ( $SECURITYGROUP ) PermissionsBoundaryName - Permissions Boundary used for creating IAM Roles; probably NGAPShRoleBoundary AWS Console See this guide for deploying the CloudFormation template using the AWS web console. You'll need three files : This file will be uploaded to the CloudFormation web console: tea-cloudformation-build.#.yaml These two zips need to be uploaded to a bucket in your account: tea-code-build.#.zip tea-dependencylayer-build.#.zip Using awscli As with AWS Console deployments, you'll need to upload the two zip files to a code bucket in your account. After doing that, be sure you've sourced the VPC and Networking parameters as well as create the two required Secrets . # Code path variables CF_TEMPLATE_FILE=/local/path/to/tea-cloudformation-build.#.yaml CODE_BUCKET=my-tea-code-bucket CODE_ARCHIVE_FILENAME=tea-code-build.#.zip DEPENDENCY_LAYER_FILENAME=tea-dependencylayer-build.#.zip BUCKETMAP_FILENAME=my_bucketmap.yaml CFG_BUCKETNAME=my-tea-cfg # See the Cloudformation parameters section above for a description of these params. STACK_NAME=my-tea # needs to be compatible with S3 naming requirements (lower case, no underscores, etc) # because the CF template may create buckets using this name. AWS_REGION=us-west-2 # Or another region if desired. AWS_PROFILE=default # Or whichever awscli profile you want to deploy to. # Deploy the stack aws cloudformation deploy --profile=${AWS_PROFILE} --region=${AWS_REGION} \\ --stack-name ${STACK_NAME} \\ --template-file ${CF_TEMPLATE_FILE} \\ --capabilities CAPABILITY_NAMED_IAM \\ --parameter-overrides \\ AuthBaseUrl=https://uat.urs.earthdata.nasa.gov \\ BucketMapFile=${BUCKETMAP_FILENAME} \\ ConfigBucket=${CFG_BUCKETNAME} \\ EnableApiGatewayLogToCloudWatch=\"False\" \\ JwtAlgo=\"RS256\" \\ JwtKeySecretName=\"jwt_secret_for_tea\" \\ LambdaCodeDependencyArchive={DEPENDENCY_LAYER_FILENAME} \\ LambdaCodeS3Bucket=${CODE_BUCKET} \\ LambdaCodeS3Key=${CODE_ARCHIVE_FILENAME} \\ LambdaTimeout=6 \\ Loglevel=INFO \\ Logtype=json \\ Maturity=DEV \\ PermissionsBoundaryName=NGAPShRoleBoundary \\ PrivateVPC=$VPCID \\ SessionTTL=168 \\ StageName=API \\ URSAuthCredsSecretName=\"urs_creds_for_tea\" \\ UseReverseBucketMap=\"False\" \\ UseCorsCookieDomain=\"False\" \\ VPCSecurityGroupIDs=$SECURITYGROUP \\ VPCSubnetIDs=$SUBNETID From Terraform Why would you want to deploy it from Terraform? Just use CloudFormation ! But for real, if someone wants to do a write up for this, I'd love to include it. From Cumulus Please see the Cumulus documentation for current TEA deployment and configuration procedures. Enabling S3 direct access TEA supports handing out s3 direct access credentials over the optional /s3credentials endpoint. This endpoint can be deployed by setting the parameter EnableS3CredentialsEndpoint=\"True\" in CloudFormation or by setting the parameter s3credentials_endpoint=true in Terraform. NOTE: Once you've deployed the CloudFormation template, you will need to manually update the API Gateway deployment if you ever want to change the value of EnableS3CredentialsEndpoint . This can also be forced in CloudFormation by adding a random number to the name of the ApiGateway Deployment resource before redeploying the stack. See S3 Direct Access for a details on how the endpoint configuration works. Post deployment procedures Once a TEA stack has been successfully deployed, there are still a few remaining steps that need to be completed before users can start downloading data. Update EDL After deploying TEA, you'll need to add the new URI to your EDL App's authorized redirect URIs. To get the proper value, you can query the cloudformation stack: aws $AWSENV cloudformation describe-stacks \\ --stack-name=$STACK_NAME \\ --query 'Stacks[0].Outputs[?OutputKey==`URSredirectURI`].OutputValue' \\ --output=text Validating a Deployment TEA has a /version endpoint you can use to check that a deployment is healthy and responsive: api_endpoint=$(aws $AWSENV cloudformation describe-stacks \\ --stack-name=$STACK_NAME \\ --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' \\ --output=text) curl ${api_endpoint}version Accessing the API Gateway inside EDC It's important to understand that in the EDC, you can't do the above step. There is no route into the VPC from the general internet. There are write-ups elsewhere that go into depth on how to proxy HTTPS requests into the private VPC. Requesting an EDC Public App To access TEA from outside the private VPC, you'll need to make a Publish New App NASD request. After the NASD has been processed and a new CloudFront domain is generated for your TEA deployment, you'll need to update the DomainName and CookieName parameters of your TEA Deployment with the new CloudFront domain name. Working inside EDC While TEA is primarily designed to be deployed inside EDC, below are some important configurations to be aware of to make deploying to EDC Successful. VPC and Networking This bash script will give you all the parameters you'll need to deploy into EDC: export AWS_REGION='us-west-2' export AWS_PROFILE='default' export AWSENV=\"--profile=${AWS_PROFILE} --region=${AWS_REGION}\" export VPCID=$(aws $AWSENV ec2 describe-vpcs --query \"Vpcs[*].VpcId\" --filters \"Name=tag:Name,Values=Application VPC\" --output text) export SUBNETID=$(aws $AWSENV ec2 describe-subnets --query \"Subnets[?VpcId=='$VPCID'].{ID:SubnetId}[0]\" --filters \"Name=tag:Name,Values=Private*\" --output=text) export SECURITYGROUP=$(aws $AWSENV ec2 describe-security-groups --query \"SecurityGroups[?VpcId=='$VPCID'].{ID:GroupId}\" --filters \"Name=tag:Name,Values=Application Default*\" --output=text) echo \"PrivateVPC=$VPCID; VPCSecurityGroupIDs=$SECURITYGROUP; VPCSubnetIDs=$SUBNETID;\" VPC Endpoints It is also important to be aware that an API Gateway VPC Endpoint will need to be setup prior to deployment. You can check to see if your account has the appropriate VPCE by running this command: aws $AWSENV ec2 describe-vpc-endpoints --query \"VpcEndpoints[?(VpcId=='$VPCID' && ServiceName=='com.amazonaws.${AWS_REGION}.execute-api')].{ID:VpcEndpointId}\" --output=text Permission Boundaries When deploying into NGAP, it is important to supply a Permission Boundary. This allows CloudFormation to create necessary IAM roles on your behalf. Do I need a Bastion? The answer is that it certainly helps. If your account does not have a bastion, validating a deployment will be very difficult.","title":"Deploying"},{"location":"deploying/#deploying","text":"It is recommended to deploy any production system using an Infrastructure As Code (IAC) solution such as terraform or AWS CloudFormation. The commands in this section exist to help you get started and understand how the TEA infrastructure works, but do not necessarily represent the best way to deploy TEA in production.","title":"Deploying"},{"location":"deploying/#quickstart","text":"You can install the TEA command line tool to get a TEA stack up and running as fast as possible. It is not recommended to use this method for production deployments.","title":"Quickstart"},{"location":"deploying/#installation","text":"We recommend using pipx to simplify virtual environment management for command line tools. pipx install provides an interface similar to pip install which means the following commands can be run using either pipx or pip if you prefer to do your own virtual environment management. To install the TEA CLI using git over SSH: pipx install git+ssh://git@github.com/asfadmin/thin-egress-app.git#subdirectory=src/tea-cli Or, to install the TEA CLI using git over HTTPS: pipx install git+https://github.com/asfadmin/thin-egress-app.git#subdirectory=src/tea-cli","title":"Installation"},{"location":"deploying/#using-the-tea-cli","text":"NOTE: For a detailed, up to date list of available functionality run: tea --help To quickly get a TEA stack up and running use the quickdeploy subcommand: tea quickdeploy This will guide you through an interactive prompt where you can choose to deploy various resources needed to set up a basic functioning TEA stack. Each step might prompt you for certain input configuration which can also be passed on the command line. See tea quickdeploy --help for a list of argument names.","title":"Using the TEA CLI"},{"location":"deploying/#getting-tea-code","text":"Major release documentation can be found on github .","title":"Getting TEA Code"},{"location":"deploying/#s3asfpubliccode","text":"All public releases of ASF code are made available via the public bucket asf.public.code . Each build has 4 files: tea-cloudformation-build.#.yaml - CloudFormation template tea-code-build.#.zip - Lambda App Python Code tea-dependencylayer-build.#.zip - Lambda layer Python Dependency Code tea-terraform-build.#.zip - TEA as a Terraform module (For cumulus!)","title":"s3://asf.public.code"},{"location":"deploying/#deployment-steps","text":"At its core, TEA uses a CloudFormation template to deploy all of its resources to AWS. Additionally, there is an available Terraform module that can be used on its own, or as an add-on to Cumulus.","title":"Deployment Steps"},{"location":"deploying/#secrets-setup","text":"Two secrets manager objects are required for TEA to function properly:","title":"Secrets Setup"},{"location":"deploying/#urs-auth-creds-secret","text":"To set up the URS Auth secret object, You'll need these parameters: UrsId can be found on your SSO application's URS home page as Client ID . UrsAuth is the UID for your URS SSO app and password separated by a colon. You can create the value with the command below. See EDL's Doumentation for more details. Encode the Creds UrsAuth=$(echo -n \"<App UID>:<App Password>\" | base64) UrsId=\"<Client ID>\" Write the base64 encoded keys into a json file: cat << EOL > urscreds.json { \"UrsId\": \"$UrsAuth\", \"UrsAuth\": \"$UrsId\" } EOL Create the secret in AWS, referencing the json file created above aws $AWSENV secretsmanager create-secret --name urs_creds_for_tea \\ --description \"URS creds for TEA app\" \\ --secret-string file://urscreds.json","title":"URS Auth Creds Secret"},{"location":"deploying/#jwt-cookie-secret","text":"JWT secrets allow multiple TEA instances to encode and decode each others JWT cookies. This helps reduce the number of times EDL Authentication needs to happen. There are many ways to create JWS Secrets, here is one example: First, Create a key pair and b64 encode them: ssh-keygen -t rsa -b 4096 -m PEM -f ./jwtcookie.key rsa_priv_key=$(openssl base64 -in jwtcookie.key -A) rsa_pub_key=$(openssl base64 -in jwtcookie.key.pub -A) Put the base-64 encoded keys into a json file like so: cat << EOL > jwtkeys.json { \"rsa_priv_key\": \"$rsa_priv_key\", \"rsa_pub_key\": \"$rsa_pub_key\" } EOL Create the secret in AWS, referencing the json file created above aws $AWSENV secretsmanager create-secret --name jwt_secret_for_tea \\ --description \"RS256 keys for TEA app JWT cookies\" \\ --secret-string file://jwtkeys.json","title":"JWT Cookie Secret"},{"location":"deploying/#from-cloudformation","text":"","title":"From CloudFormation"},{"location":"deploying/#all-parameters","text":"App Settings : Loglevel - How verbose the logging should be Logtype - How log entries are formed. Use json in conjunction with log analysis tools. Use flat for human debugging. Maturity - Maturity, mostly for logs ConfigBucket - S3 bucket where configuration files (bucket map, templates) are kept HtmlTemplateDir - (OPTIONAL) Subdirectory of ConfigBucket where templates can be found StageName - API Gateway Stage value EnableApiGatewayLogToCloudWatch - Whether or not API Gateway logs should be dumped EnableS3CredentialsEndpoint - Whether or not to deploy the /s3credentials endpoint for s3 direct access. Domain Settings : DomainName - (OPTIONAL) domain name as a user will access it (ie CloudFront, CNAME, etc) CookieDomain - (OPTIONAL) domain name value for minting cookies DomainCertArn - (OPTIONAL) Arn to a AWS ACM SSL Cert for HTTPS access UseCorsCookieDomain - If True , and CookieDomain is set, this enables CORS Response Headers Lambda Code : LambdaCodeS3Bucket - S3 bucket where Lambda code zip files are kept LambdaCodeS3Key - Object name of Lambda code zip LambdaCodeDependencyArchive - Object name of Lambda Dependency Layer zip LambdaTimeout - Lambda timeout in seconds LambdaMemory - The amount of memory available to the function during execution. Must be multiple of 64. Minimum: 128. Max: 3008. Default 1792. URS Settings : URSAuthCredsSecretName - URS Auth Creds Secret AuthBaseUrl - Which maturity of URS to hit Data Bucket Setup : BucketnamePrefix - (OPTIONAL) Bucket prefix value (see Bucket Mapping ) BucketMapFile - bucket map YAML file (see Bucket Mapping ) UseReverseBucketMap - Ignore this value! DownloadRoleArn - (OPTIONAL) Pre-created IAM Role for minting presigned urls Leave blank to create a new role for deployment DownloadRoleInRegionArn - (OPTIONAL) Pre-created IAM Role for minting IN-REGION presigned urls Leave blank to create a new role for deployment SuppressHeadCheck - Disable the pre-sign object validation. Enable for speedier access. Session Settings : SessionTTL - How long, in seconds, JWT Cookies are valid for JwtAlgo - JWT Signing algorithm JwtKeySecretName - JWT Cookie Secret NGAP Integration : \u26a0\ufe0f These are REQUIRED for EDC Deployments. See VPC and Networking PrivateVPC - Private VPC ID in which we create resources ( $VPCID ) VPCSecurityGroupIDs - Security group ( $SUBNETID ) VPCSubnetIDs - VPC Subnets to deploy into ( $SECURITYGROUP ) PermissionsBoundaryName - Permissions Boundary used for creating IAM Roles; probably NGAPShRoleBoundary","title":"All Parameters"},{"location":"deploying/#aws-console","text":"See this guide for deploying the CloudFormation template using the AWS web console. You'll need three files : This file will be uploaded to the CloudFormation web console: tea-cloudformation-build.#.yaml These two zips need to be uploaded to a bucket in your account: tea-code-build.#.zip tea-dependencylayer-build.#.zip","title":"AWS Console"},{"location":"deploying/#using-awscli","text":"As with AWS Console deployments, you'll need to upload the two zip files to a code bucket in your account. After doing that, be sure you've sourced the VPC and Networking parameters as well as create the two required Secrets . # Code path variables CF_TEMPLATE_FILE=/local/path/to/tea-cloudformation-build.#.yaml CODE_BUCKET=my-tea-code-bucket CODE_ARCHIVE_FILENAME=tea-code-build.#.zip DEPENDENCY_LAYER_FILENAME=tea-dependencylayer-build.#.zip BUCKETMAP_FILENAME=my_bucketmap.yaml CFG_BUCKETNAME=my-tea-cfg # See the Cloudformation parameters section above for a description of these params. STACK_NAME=my-tea # needs to be compatible with S3 naming requirements (lower case, no underscores, etc) # because the CF template may create buckets using this name. AWS_REGION=us-west-2 # Or another region if desired. AWS_PROFILE=default # Or whichever awscli profile you want to deploy to. # Deploy the stack aws cloudformation deploy --profile=${AWS_PROFILE} --region=${AWS_REGION} \\ --stack-name ${STACK_NAME} \\ --template-file ${CF_TEMPLATE_FILE} \\ --capabilities CAPABILITY_NAMED_IAM \\ --parameter-overrides \\ AuthBaseUrl=https://uat.urs.earthdata.nasa.gov \\ BucketMapFile=${BUCKETMAP_FILENAME} \\ ConfigBucket=${CFG_BUCKETNAME} \\ EnableApiGatewayLogToCloudWatch=\"False\" \\ JwtAlgo=\"RS256\" \\ JwtKeySecretName=\"jwt_secret_for_tea\" \\ LambdaCodeDependencyArchive={DEPENDENCY_LAYER_FILENAME} \\ LambdaCodeS3Bucket=${CODE_BUCKET} \\ LambdaCodeS3Key=${CODE_ARCHIVE_FILENAME} \\ LambdaTimeout=6 \\ Loglevel=INFO \\ Logtype=json \\ Maturity=DEV \\ PermissionsBoundaryName=NGAPShRoleBoundary \\ PrivateVPC=$VPCID \\ SessionTTL=168 \\ StageName=API \\ URSAuthCredsSecretName=\"urs_creds_for_tea\" \\ UseReverseBucketMap=\"False\" \\ UseCorsCookieDomain=\"False\" \\ VPCSecurityGroupIDs=$SECURITYGROUP \\ VPCSubnetIDs=$SUBNETID","title":"Using awscli"},{"location":"deploying/#from-terraform","text":"Why would you want to deploy it from Terraform? Just use CloudFormation ! But for real, if someone wants to do a write up for this, I'd love to include it.","title":"From Terraform"},{"location":"deploying/#from-cumulus","text":"Please see the Cumulus documentation for current TEA deployment and configuration procedures.","title":"From Cumulus"},{"location":"deploying/#enabling-s3-direct-access","text":"TEA supports handing out s3 direct access credentials over the optional /s3credentials endpoint. This endpoint can be deployed by setting the parameter EnableS3CredentialsEndpoint=\"True\" in CloudFormation or by setting the parameter s3credentials_endpoint=true in Terraform. NOTE: Once you've deployed the CloudFormation template, you will need to manually update the API Gateway deployment if you ever want to change the value of EnableS3CredentialsEndpoint . This can also be forced in CloudFormation by adding a random number to the name of the ApiGateway Deployment resource before redeploying the stack. See S3 Direct Access for a details on how the endpoint configuration works.","title":"Enabling S3 direct access"},{"location":"deploying/#post-deployment-procedures","text":"Once a TEA stack has been successfully deployed, there are still a few remaining steps that need to be completed before users can start downloading data.","title":"Post deployment procedures"},{"location":"deploying/#update-edl","text":"After deploying TEA, you'll need to add the new URI to your EDL App's authorized redirect URIs. To get the proper value, you can query the cloudformation stack: aws $AWSENV cloudformation describe-stacks \\ --stack-name=$STACK_NAME \\ --query 'Stacks[0].Outputs[?OutputKey==`URSredirectURI`].OutputValue' \\ --output=text","title":"Update EDL"},{"location":"deploying/#validating-a-deployment","text":"TEA has a /version endpoint you can use to check that a deployment is healthy and responsive: api_endpoint=$(aws $AWSENV cloudformation describe-stacks \\ --stack-name=$STACK_NAME \\ --query 'Stacks[0].Outputs[?OutputKey==`ApiEndpoint`].OutputValue' \\ --output=text) curl ${api_endpoint}version","title":"Validating a Deployment"},{"location":"deploying/#accessing-the-api-gateway-inside-edc","text":"It's important to understand that in the EDC, you can't do the above step. There is no route into the VPC from the general internet. There are write-ups elsewhere that go into depth on how to proxy HTTPS requests into the private VPC.","title":"Accessing the API Gateway inside EDC"},{"location":"deploying/#requesting-an-edc-public-app","text":"To access TEA from outside the private VPC, you'll need to make a Publish New App NASD request. After the NASD has been processed and a new CloudFront domain is generated for your TEA deployment, you'll need to update the DomainName and CookieName parameters of your TEA Deployment with the new CloudFront domain name.","title":"Requesting an EDC Public App"},{"location":"deploying/#working-inside-edc","text":"While TEA is primarily designed to be deployed inside EDC, below are some important configurations to be aware of to make deploying to EDC Successful.","title":"Working inside EDC"},{"location":"deploying/#vpc-and-networking","text":"This bash script will give you all the parameters you'll need to deploy into EDC: export AWS_REGION='us-west-2' export AWS_PROFILE='default' export AWSENV=\"--profile=${AWS_PROFILE} --region=${AWS_REGION}\" export VPCID=$(aws $AWSENV ec2 describe-vpcs --query \"Vpcs[*].VpcId\" --filters \"Name=tag:Name,Values=Application VPC\" --output text) export SUBNETID=$(aws $AWSENV ec2 describe-subnets --query \"Subnets[?VpcId=='$VPCID'].{ID:SubnetId}[0]\" --filters \"Name=tag:Name,Values=Private*\" --output=text) export SECURITYGROUP=$(aws $AWSENV ec2 describe-security-groups --query \"SecurityGroups[?VpcId=='$VPCID'].{ID:GroupId}\" --filters \"Name=tag:Name,Values=Application Default*\" --output=text) echo \"PrivateVPC=$VPCID; VPCSecurityGroupIDs=$SECURITYGROUP; VPCSubnetIDs=$SUBNETID;\"","title":"VPC and Networking"},{"location":"deploying/#vpc-endpoints","text":"It is also important to be aware that an API Gateway VPC Endpoint will need to be setup prior to deployment. You can check to see if your account has the appropriate VPCE by running this command: aws $AWSENV ec2 describe-vpc-endpoints --query \"VpcEndpoints[?(VpcId=='$VPCID' && ServiceName=='com.amazonaws.${AWS_REGION}.execute-api')].{ID:VpcEndpointId}\" --output=text","title":"VPC Endpoints"},{"location":"deploying/#permission-boundaries","text":"When deploying into NGAP, it is important to supply a Permission Boundary. This allows CloudFormation to create necessary IAM roles on your behalf.","title":"Permission Boundaries"},{"location":"deploying/#do-i-need-a-bastion","text":"The answer is that it certainly helps. If your account does not have a bastion, validating a deployment will be very difficult.","title":"Do I need a Bastion?"},{"location":"s3access/","text":"S3 Direct Access You can retrieve temporary S3 credentials at the /s3credentials endpoint when authenticated via Earthdata Login. These credentials will only be valid for 1 hour due to role chaining and can be used make in-region s3:ListBucket and s3:GetObject requests. Your code must handle expired tokens and request new ones as needed for sessions that exceed this 1 hour limit. Request Credentials are retrieved through an HTTP GET request to the /s3credentials endpoint. The request must be authenticated with either a JWT token for TEA or by using EDL Bearer Tokens . Unauthenticated requests will be redirected to EDL. Headers: (optional) app-name : An arbitrary string to include in the generated role session name for metric reporting purposes. It can only contain characters that are valid in a RoleSessionName see the AssumeRole documentation . It is recommended to include this header when making requests on users behalf from another cloud service. The generated role session name is username@app-name . Example: import requests resp = requests.get( \"https://your-tea-host/s3credentials\", headers={\"app-name\": \"my-application\"}, cookies={\"asf-urs\": \"<your jwt token>\"} ) print(resp.json()) Response The response is your temporary credentials as returned by Amazon STS. See the AWS Credentials reference for more details. Example: { \"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\", \"secretAccessKey\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\", \"sessionToken\": \"LONGSTRINGOFCHARACTERS.../HJLgV91QJFCMlmY8slIEOjrOChLQYmzAqrb5U1ekoQAK6f86HKJFTT2dONzPgmJN9ZvW5DBwt6XUxC9HAQ0LDPEYEwbjGVKkzSNQh/\", \"expiration\": \"2021-01-27 00:50:09+00:00\" } Using Temporary Credentials To use the credentials you must configure your AWS SDK library with the returned access key, secret and token. Note that the credentials are only valid for in-region requests, so using them with your AWS CLI will not work! You must make your requests from an AWS service such as Lambda or EC2 in the same region as the source bucket you are pulling from. See Using temporary credentials with AWS resources for more information on how to use your temporary credentials. Example: This example lambda function uses EDL Bearer Tokens to obtain s3 credentials and stream an object from one bucket to another. The lambda execution role will need s3:PutObject permissions on the destination bucket. import boto3 import json import urllib.request def lambda_handler(event, context): # Get temporary download credentials tea_url = event[\"CredentialsEndpoint\"] bearer_token = event[\"BearerToken\"] req = urllib.request.Request( url=tea_url, headers={\"Authorization\": f\"Bearer {bearer_token}\"} ) with urllib.request.urlopen(req) as f: creds = json.loads(f.read().decode()) # Set up separate boto3 clients for download and upload download_client = boto3.client( \"s3\", aws_access_key_id=creds[\"accessKeyId\"], aws_secret_access_key=creds[\"secretAccessKey\"], aws_session_token=creds[\"sessionToken\"] ) # Lambda needs to have permission to upload to destination bucket upload_client = boto3.client(\"s3\") # Stream from the source bucket to the destination bucket resp = download_client.get_object( Bucket=event[\"Source\"][\"Bucket\"], Key=event[\"Source\"][\"Key\"], ) upload_client.upload_fileobj( resp[\"Body\"], event[\"Dest\"][\"Bucket\"], event[\"Dest\"].get(\"Key\") or event[\"Source\"][\"Key\"], ) The example can be invoked with an event payload as follows: { \"CredentialsEndpoint\": \"https://your-tea-host/s3credentials\", \"BearerToken\": \"your bearer token\", \"Source\": { \"Bucket\": \"S3 bucket name from CMR link\", \"Key\": \"S3 key from CMR link\" }, \"Dest\": { \"Bucket\": \"S3 bucket name to copy to\" } }","title":"S3 Access"},{"location":"s3access/#s3-direct-access","text":"You can retrieve temporary S3 credentials at the /s3credentials endpoint when authenticated via Earthdata Login. These credentials will only be valid for 1 hour due to role chaining and can be used make in-region s3:ListBucket and s3:GetObject requests. Your code must handle expired tokens and request new ones as needed for sessions that exceed this 1 hour limit.","title":"S3 Direct Access"},{"location":"s3access/#request","text":"Credentials are retrieved through an HTTP GET request to the /s3credentials endpoint. The request must be authenticated with either a JWT token for TEA or by using EDL Bearer Tokens . Unauthenticated requests will be redirected to EDL. Headers: (optional) app-name : An arbitrary string to include in the generated role session name for metric reporting purposes. It can only contain characters that are valid in a RoleSessionName see the AssumeRole documentation . It is recommended to include this header when making requests on users behalf from another cloud service. The generated role session name is username@app-name . Example: import requests resp = requests.get( \"https://your-tea-host/s3credentials\", headers={\"app-name\": \"my-application\"}, cookies={\"asf-urs\": \"<your jwt token>\"} ) print(resp.json())","title":"Request"},{"location":"s3access/#response","text":"The response is your temporary credentials as returned by Amazon STS. See the AWS Credentials reference for more details. Example: { \"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\", \"secretAccessKey\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\", \"sessionToken\": \"LONGSTRINGOFCHARACTERS.../HJLgV91QJFCMlmY8slIEOjrOChLQYmzAqrb5U1ekoQAK6f86HKJFTT2dONzPgmJN9ZvW5DBwt6XUxC9HAQ0LDPEYEwbjGVKkzSNQh/\", \"expiration\": \"2021-01-27 00:50:09+00:00\" }","title":"Response"},{"location":"s3access/#using-temporary-credentials","text":"To use the credentials you must configure your AWS SDK library with the returned access key, secret and token. Note that the credentials are only valid for in-region requests, so using them with your AWS CLI will not work! You must make your requests from an AWS service such as Lambda or EC2 in the same region as the source bucket you are pulling from. See Using temporary credentials with AWS resources for more information on how to use your temporary credentials. Example: This example lambda function uses EDL Bearer Tokens to obtain s3 credentials and stream an object from one bucket to another. The lambda execution role will need s3:PutObject permissions on the destination bucket. import boto3 import json import urllib.request def lambda_handler(event, context): # Get temporary download credentials tea_url = event[\"CredentialsEndpoint\"] bearer_token = event[\"BearerToken\"] req = urllib.request.Request( url=tea_url, headers={\"Authorization\": f\"Bearer {bearer_token}\"} ) with urllib.request.urlopen(req) as f: creds = json.loads(f.read().decode()) # Set up separate boto3 clients for download and upload download_client = boto3.client( \"s3\", aws_access_key_id=creds[\"accessKeyId\"], aws_secret_access_key=creds[\"secretAccessKey\"], aws_session_token=creds[\"sessionToken\"] ) # Lambda needs to have permission to upload to destination bucket upload_client = boto3.client(\"s3\") # Stream from the source bucket to the destination bucket resp = download_client.get_object( Bucket=event[\"Source\"][\"Bucket\"], Key=event[\"Source\"][\"Key\"], ) upload_client.upload_fileobj( resp[\"Body\"], event[\"Dest\"][\"Bucket\"], event[\"Dest\"].get(\"Key\") or event[\"Source\"][\"Key\"], ) The example can be invoked with an event payload as follows: { \"CredentialsEndpoint\": \"https://your-tea-host/s3credentials\", \"BearerToken\": \"your bearer token\", \"Source\": { \"Bucket\": \"S3 bucket name from CMR link\", \"Key\": \"S3 key from CMR link\" }, \"Dest\": { \"Bucket\": \"S3 bucket name to copy to\" } }","title":"Using Temporary Credentials"},{"location":"technical/","text":"Technical System Architecture TEA is a Python Chalice application that leverages AWS Lambda and API Gateway to create Pre-signed S3 URLs to facilitate user downloads over https via CloudFront. Dynamic In-Region IP CIDR Updates TEA deploys a Lambda, triggered by a subscription to the SNS Topic arn::aws:sns:us-east-1:806199016981:AmazonIpSpaceChanged , which downloads the AWS Provided ip-ranges.json file, parses out the IP CIDRs for the deploy region, and automatically updates the In-Region IAM Role's Policy Document condition block. This lambda is defined in update_lambda.py Build Process Code Quality TEA leverages several open source platforms along with mandatory peer code review to help ensure the code base is clean, stable, and secure. Linting CodeFactor.io github integrations provide merge request blocking based on appropriate levels of code linting. CVE PyUp, Snyk and Whitesource all provide Common Vulnerabilities and Exposures (CVE) Analysis. Emergent CVE fixes are automatically pushed to the TEA repo as pull requests and merged into the repo as soon as possible. Static Code Analysis CodeFactor.io and Whitesource provide merge request block based on Static Code Analysis to help ensure our code is secure and safe to run. External Integrations TEA cannot really operate in a vacuum. TEA is part of what might be considered the Earthdata ecosystem. Cumulus TEA can be considered the \"official\" distribution application of Cumulus, and while there is a symbiotic relationship, TEA is an add-on to cumulus rather than an extension. We suggest utilizing the applicable Cumulus documentation for tightly coupled TEA+Cumulus deployments. EDL The Earthdata Login OAUTH service is a requirement for distributing data where user activity tracking and reporting is required. Before deploying TEA, it is important to have access to, or create a new EDL Application . Creating and administrating an EDL Application requires the EDL App Admin role, which must be requested through the feedback modal in the Earthdata login header menu. EDC While TEA can be deployed outside of the Earthdata Cloud, it is designed and intended to be used within the Earthdata Cloud environment. While we assume you'll be deploying to the EDC, we cannot provide assistance in setting up or configuring access to EDC. However, when there are steps or considerations that are required for integration into EDC, we will help ensure you have all the information you need to do the right thing.","title":"Technical"},{"location":"technical/#technical","text":"","title":"Technical"},{"location":"technical/#system-architecture","text":"TEA is a Python Chalice application that leverages AWS Lambda and API Gateway to create Pre-signed S3 URLs to facilitate user downloads over https via CloudFront.","title":"System Architecture"},{"location":"technical/#dynamic-in-region-ip-cidr-updates","text":"TEA deploys a Lambda, triggered by a subscription to the SNS Topic arn::aws:sns:us-east-1:806199016981:AmazonIpSpaceChanged , which downloads the AWS Provided ip-ranges.json file, parses out the IP CIDRs for the deploy region, and automatically updates the In-Region IAM Role's Policy Document condition block. This lambda is defined in update_lambda.py","title":"Dynamic In-Region IP CIDR Updates"},{"location":"technical/#build-process","text":"","title":"Build Process"},{"location":"technical/#code-quality","text":"TEA leverages several open source platforms along with mandatory peer code review to help ensure the code base is clean, stable, and secure.","title":"Code Quality"},{"location":"technical/#linting","text":"CodeFactor.io github integrations provide merge request blocking based on appropriate levels of code linting.","title":"Linting"},{"location":"technical/#cve","text":"PyUp, Snyk and Whitesource all provide Common Vulnerabilities and Exposures (CVE) Analysis. Emergent CVE fixes are automatically pushed to the TEA repo as pull requests and merged into the repo as soon as possible.","title":"CVE"},{"location":"technical/#static-code-analysis","text":"CodeFactor.io and Whitesource provide merge request block based on Static Code Analysis to help ensure our code is secure and safe to run.","title":"Static Code Analysis"},{"location":"technical/#external-integrations","text":"TEA cannot really operate in a vacuum. TEA is part of what might be considered the Earthdata ecosystem.","title":"External Integrations"},{"location":"technical/#cumulus","text":"TEA can be considered the \"official\" distribution application of Cumulus, and while there is a symbiotic relationship, TEA is an add-on to cumulus rather than an extension. We suggest utilizing the applicable Cumulus documentation for tightly coupled TEA+Cumulus deployments.","title":"Cumulus"},{"location":"technical/#edl","text":"The Earthdata Login OAUTH service is a requirement for distributing data where user activity tracking and reporting is required. Before deploying TEA, it is important to have access to, or create a new EDL Application . Creating and administrating an EDL Application requires the EDL App Admin role, which must be requested through the feedback modal in the Earthdata login header menu.","title":"EDL"},{"location":"technical/#edc","text":"While TEA can be deployed outside of the Earthdata Cloud, it is designed and intended to be used within the Earthdata Cloud environment. While we assume you'll be deploying to the EDC, we cannot provide assistance in setting up or configuring access to EDC. However, when there are steps or considerations that are required for integration into EDC, we will help ensure you have all the information you need to do the right thing.","title":"EDC"},{"location":"troubleshooting/","text":"Troubleshooting When things go wrong There is a lot that can go wrong, but we hope that if you followed this guide, you'll have prevented many of the common problems. If not, start here! Error message: If you see an error message in the Cloudformation Events like this: CloudWatch Logs role ARN must be set in account settings to enable logging (Service: AmazonApiGateway; Status Code: 400; Error Code: BadRequestException; ... Solution: EnableApiGatewayLogToCloudWatch is set to True . If you don't need API Gateway logging to cloudwatch, set to False . If you do, you must create a role with write access to Cloudwatch Logs and add its ARN here: https://console.aws.amazon.com/apigateway/home?region=<REGION>#/settings . Updating Cached Values: For efficiency, TEA will cache configuration into the Lambda run environment. Certain changes, like modifications to the bucket map or secrets, may not be immediately picked up. Lambda run times will eventually time out, but you can force refetching of cached values be simply adding a dummy environment variable to the running Lambda environment. There may be a better way to trigger Lambda environment flushing, lets us know if you find a way. Logs The two primary locations where you can see the affects of TEA in the logs. CloudWatch Logs TEA Creates two log streams: /aws/lambda/<STACK_NAME>-EgressLambda - This is where App logs go /aws/lambda/<STACK_NAME>-UpdatePolicyLambda - Logs from the Lambda that keeps the in-region CIDR list up to date in the in-region download role. Values embedded into S3 logs When TEA generates a pre-signed S3 download URL, it adds a query parameter A-userid , the value of which is the EDL User ID, if any, that was used to download the data. This parameter is available to be mined out of the S3 access logs. When CloudFront is deployed in front of TEA, that A-userid parameters is also added to the s3 download request that CloudFront generates. CloudFront will also add a sourceip parameter that holds the true IP of the external user. Bug reporting/tracking First step when you encounter an error is to check the Troubleshooting section. If your problem is not there, feel free to reach out in the #tea-pot Slack Channel. If your problem can't be resolved, we'll put in a Github Issue to help track the problem and seek resolution.","title":"Trouble Shooting"},{"location":"troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"troubleshooting/#when-things-go-wrong","text":"There is a lot that can go wrong, but we hope that if you followed this guide, you'll have prevented many of the common problems. If not, start here!","title":"When things go wrong"},{"location":"troubleshooting/#error-message","text":"If you see an error message in the Cloudformation Events like this: CloudWatch Logs role ARN must be set in account settings to enable logging (Service: AmazonApiGateway; Status Code: 400; Error Code: BadRequestException; ...","title":"Error message:"},{"location":"troubleshooting/#solution","text":"EnableApiGatewayLogToCloudWatch is set to True . If you don't need API Gateway logging to cloudwatch, set to False . If you do, you must create a role with write access to Cloudwatch Logs and add its ARN here: https://console.aws.amazon.com/apigateway/home?region=<REGION>#/settings .","title":"Solution:"},{"location":"troubleshooting/#updating-cached-values","text":"For efficiency, TEA will cache configuration into the Lambda run environment. Certain changes, like modifications to the bucket map or secrets, may not be immediately picked up. Lambda run times will eventually time out, but you can force refetching of cached values be simply adding a dummy environment variable to the running Lambda environment. There may be a better way to trigger Lambda environment flushing, lets us know if you find a way.","title":"Updating Cached Values:"},{"location":"troubleshooting/#logs","text":"The two primary locations where you can see the affects of TEA in the logs.","title":"Logs"},{"location":"troubleshooting/#cloudwatch-logs","text":"TEA Creates two log streams: /aws/lambda/<STACK_NAME>-EgressLambda - This is where App logs go /aws/lambda/<STACK_NAME>-UpdatePolicyLambda - Logs from the Lambda that keeps the in-region CIDR list up to date in the in-region download role.","title":"CloudWatch Logs"},{"location":"troubleshooting/#values-embedded-into-s3-logs","text":"When TEA generates a pre-signed S3 download URL, it adds a query parameter A-userid , the value of which is the EDL User ID, if any, that was used to download the data. This parameter is available to be mined out of the S3 access logs. When CloudFront is deployed in front of TEA, that A-userid parameters is also added to the s3 download request that CloudFront generates. CloudFront will also add a sourceip parameter that holds the true IP of the external user.","title":"Values embedded into S3 logs"},{"location":"troubleshooting/#bug-reportingtracking","text":"First step when you encounter an error is to check the Troubleshooting section. If your problem is not there, feel free to reach out in the #tea-pot Slack Channel. If your problem can't be resolved, we'll put in a Github Issue to help track the problem and seek resolution.","title":"Bug reporting/tracking"},{"location":"vision/","text":"Vision We the TEA m strive to create the simplest, most reliable, most feature-rich S3 distribution app. Our intent is not to provide EVERY feature imaginable, but to maintain the THIN core of broadly applicable features. We want to continue to engage the user community to improve the feature set while staunchly resisting the siren song of feature bloat and one-off special ponies. Principles of TEA design Keep it simple - No special ponies! Remove unwanted/unused code Write clean code Engage and support the community Strive for 10% community provided code base - we \u2764\ufe0f PR's!","title":"Vision"},{"location":"vision/#vision","text":"We the TEA m strive to create the simplest, most reliable, most feature-rich S3 distribution app. Our intent is not to provide EVERY feature imaginable, but to maintain the THIN core of broadly applicable features. We want to continue to engage the user community to improve the feature set while staunchly resisting the siren song of feature bloat and one-off special ponies.","title":"Vision"},{"location":"vision/#principles-of-tea-design","text":"Keep it simple - No special ponies! Remove unwanted/unused code Write clean code Engage and support the community Strive for 10% community provided code base - we \u2764\ufe0f PR's!","title":"Principles of TEA design"}]}